---
title: "Credit Scoring [pt2]"
author: "Felipe Daiha Alves"
date: "5 de fevereiro de 2021"
output: html_document
---


Parte 2 - Machine Learning & mais Feature Engineering


[REVENDO...] Carregando Pacotes
```{r Carregando Pacotes, message=FALSE, warning=FALSE, include=FALSE}
library("dplyr", lib.loc="~/R/win-library/3.6")  ## Manipulacao de Dados
library("ggplot2", lib.loc="~/R/win-library/3.6") ## Visualizacao Grafica dos Dados
library("scales", lib.loc="~/R/win-library/3.6") ## Permite alteracao da escala dos graficos
library("cowplot", lib.loc="~/R/win-library/3.6") ## Cria graficos em grid
library("caTools", lib.loc = "~/R/win-library/3.6") ## Divisao Base de Treinamento e Teste
library("ROSE", lib.loc="~/R/win-library/3.6") ## Balanceia a quantidade de classes do target
library("data.table", lib.loc="~/R/win-library/3.6") ## Verifica a consistencia dos DBs Treino-Teste
library("randomForest", lib.loc="~/R/win-library/3.6") ## Contem o algoritmo do Random Forest
library("caret", lib.loc="~/R/win-library/3.6") ## Gera a Matriz Confusao
library("mltools", lib.loc="~/R/win-library/3.6") ## Analisa Metricas Estatisticas de um modelo de ML
library("MLmetrics", lib.loc="~/R/win-library/3.6") ## Outras Metricas Estatisticas de ML
```


[REVENDO...] Upload da Base de Dados
```{r Upload da Base de Dados, include=FALSE}
CreditScoring = read.csv("C:/Users/felip/Desktop/CreditScoring.csv")
```


[REVENDO...] Criando uma copia do DB para limpeza dos dados
```{r Limpeza de Dados, include=FALSE}
# Gerando uma copia:

db = CreditScoring


# Excluindo as colunas 'education', 'numberOfDependents', 'flagOtherCard', 'quantityBankingAccounts',  'flagMobilePhone', 'flagContactPhone', 'codeApplicationBooth'.

db = select(db, -c(education, numberOfDependents, flagOtherCard, quantityBankingAccounts, flagMobilePhone, flagContactPhone, codeApplicationBooth))


# Excluindo os registros vazios de 'gender'

db = db %>%
  select_all() %>%
  filter(gender != "")


# Verificando as mudancas

dim(db)

  ## As demais variaveis serao plotadas em um grafico de barras para analisar sua       distribuicao e frequencia
```


[REVENDO...] Verificando Quantiles para Analise de Outliers e algumas Variaveis Continuas
```{r Verificando Quantiles para Analise de Outliers e algumas Variaveis Continuas, include=FALSE}

out_list = list("monthsInTheJob", "mateIncome", "personalNetIncome",
                "monthsInResidence")

for (i in out_list) {
  x = quantile(CreditScoring[, i])
  print(i)
  print(x)
}

  ## As classes mateIncome. personalNetIncome apresentam registros do Q4 muito       deslocados da mediana do dataset. Vamos verificar sua totalidade no db.


# Analisando registros > 0 e sua distribuicao no db

 for (i in out_list) {
    a = CreditScoring %>% 
        select(i, BAD) %>% 
        filter(CreditScoring[, i] > 0)
    print(i)
    print(table(a$BAD))
 }


# Eliminando o campo 'mateIncome':

db$mateIncome = NULL

  ## A classe mateIncome apresenta poucos registros comparados com a totalidade do db. Dessa forma, vamos elimina-la!
  ## Para os outros campos, sera feito um tratamento de outlier pela IQR Rule.
```


[REVENDO...] Tratando Outliers
```{r Tratando Outliers, include=FALSE}

# (1) monthsInTheJob:

  left_mITJ_otl = quantile(db$monthsInTheJob)[2] - 
                            1.5 * IQR(db$monthsInTheJob) 
  right_mITJ_otl = quantile(db$monthsInTheJob)[4] + 
                             1.5*IQR(db$monthsInTheJob)

  db$monthsInTheJob[db$monthsInTheJob > right_mITJ_otl] = right_mITJ_otl
  
  
# (2) personalNetIncome:

  left_pNI_otl = quantile(db$personalNetIncome)[2] - 
                            1.5 * IQR(db$personalNetIncome) 
  right_pNI_otl = quantile(db$personalNetIncome)[4] + 
                             1.5*IQR(db$personalNetIncome)

  db$personalNetIncome[db$personalNetIncome > right_pNI_otl] = right_pNI_otl
  
# (3) monthsInTheJob:

  left_mIR_otl = quantile(db$monthsInResidence)[2] - 
                            1.5 * IQR(db$monthsInResidence) 
  right_mIR_otl = quantile(db$monthsInResidence)[4] + 
                             1.5*IQR(db$monthsInResidence)

  db$monthsInResidence[db$monthsInResidence > right_mIR_otl] = right_mIR_otl
```


[REVENDO...] Transformando algumas classes
```{r Transformando algumas classes, include=FALSE}
db$BAD = as.factor(db$BAD)
db$age = as.numeric(db$age)
db$bestPaymentDay = as.numeric(db$bestPaymentDay)
db$monthsInTheJob = as.numeric(db$monthsInTheJob)
db$personalNetIncome = as.numeric(db$personalNetIncome)
db$shopRank = as.factor(db$shopRank)

# Verificando as mudancas
lapply(db, class)

```


Feature Engineering: Criando outro db para utilizacao de modelos de Machine Learning
```{r Criando outro db para mais uma etapa de Feature Engineering}

# Gerando uma copia do db

db_scale = db


# Excluindo as colunas que nao serao utilizadas em ML

db_scale = select(db_scale, -c(X, clientId, shopId, areaCodeResidencialPhone, 
                               shopRank, flagMothersName, flagFathersName,
                               flagResidenceState_WorkingState, professionCode, 
                               flagResidencialAddress_PostalAddress))

  ## A analise exploratoria verificou que essas colunas nao estabeleciam relacoes        importantes como um todo com a variavel target.


# Fazendo um One Hot Encoding para ganho de informacao:

db_scale$BAD =  NULL
db_scale = as.data.frame(one_hot(as.data.table(db_scale)))


# Transformando as variaveis de integer para factor

cols = c(2:8, 10:11, 13:16, 18:19)
db_scale[, cols] = lapply(db_scale[,cols] , factor)


# Eliminando/Adicionando colunas finais

db_scale$gender_ = NULL
db_scale$BAD = db$BAD


# Cruzando algumas features (Essas informacoes foram coletadas por retroalimentacao do modelo: 1 - Testava-se o modelo; 2 - Observava o Feature Importance; 3 - Analisava ganhos/perdas com novas variaveis, e assim sucessivamente ate chegar nesses cruzamentos e novas variaveis):

  ## (1) 'monthsInResidence' + 'monthsInTheJob':

  db_scale$sumMIR_MITJ = db_scale$monthsInResidence + db_scale$monthsInTheJob
  
  ## (2) 'personalNetIncome' x 'age':
  
  db_scale$multPNI_AGe = db_scale$personalNetIncome * db_scale$age
  
  ## (3) 'areaCodeResidencialPhone' == 31 ou 50
  
  db_scale$aCRP31 = ifelse(db$areaCodeResidencialPhone == 31, 1, 0)
    db_scale$aCRP31 = as.factor(db_scale$aCRP31)
    
  db_scale$aCRP50 = ifelse(db$areaCodeResidencialPhone == 50, 1, 0)
    db_scale$aCRP50 = as.factor(db_scale$aCRP50)

  ## (4) 'professionCode' == 950 ou 999

  db_scale$pC950 = ifelse(db$professionCode == 950, 1, 0)
    db_scale$pC950 = as.factor(db_scale$pC950)
    
  db_scale$pC999 = ifelse(db$professionCode == 999, 1, 0)
    db_scale$pC999 = as.factor(db_scale$pC999)
```


Grafico de Frequencia das Classes 0 e 1 do target
```{r Gráfico de Frequencia das Classes 0 e 1 do target}
# Gerando um grafico de frequencia absoluta para verificar o balanceamento das classes:

BAD_balanced_plot = ggplot(db, aes(x = BAD)) +
  geom_bar(width = 0.5) +
  labs(title = "Frequency BAD Classes") +
  theme_classic() +
  geom_text(aes(label = scales::percent((..count..)/sum(..count..)),
            y= ((..count..)/sum(..count..))), stat="count",
        vjust = -1, colour = "white", size = 5)
BAD_balanced_plot 

  ## Ha uma quantidade significativa de 0 em relacao a 1. Deve-se tomar cuidado na hora de construir um modelo.

# Em quantidade absoluta:

table(db$BAD)
```


Split da Base em Treino e Teste balanceado
```{r Split da Base em Treino e Teste}
# Criando a "semente geradora" e dividindo a Base de Dados em Treino-Teste:

set.seed(1)


db_scale$X = db$X


split_db = sample.split(db_scale$X, SplitRatio = 0.75) 
  ## Divide a base de dados aleatoriamente segundo a variavel 'X' em fracoes TRUE     (75%) e FALSE (25%).

train_db = subset(db_scale, split_db == TRUE)
train_db$X = NULL
  ## Define que os valores TRUE pertencem ao DB treino

test_db = subset(db_scale, split_db == FALSE)
test_db$X = NULL
  ## Define que os valores FALSE pertencem ao DB teste

```


Verificando se Treino-Teste esta balanceado ao db original
```{r Verificando se Treino-Teste esta balanceado corretamente}
check_train = setDT(train_db)[,.N/nrow(train_db),BAD]
check_train

check_test = setDT(test_db)[,.N/nrow(test_db),BAD]
check_test

    ## Esta balanceado proporcionalmente a base de dados original!
```


Tratando base de dados desbalanceada em target
```{r Tratando base de dados desbalanceada em target}
# Utilizando o recurso de geracao de dados sinteticos para classificacoes binarias de classes desbalanceadas do pacote 'ROSE'

db_balanced = ROSE(BAD ~ ., data = train_db, seed = 1, hmult.majo = 0.02,
                   hmult.mino = 0.01)$data


# Verificando a distribuicao

table(db_balanced$BAD)
```


Fazendo validacao cruzada para a construcao do modelo
```{r Cross Validation}

# Definindo um train control a ser utilizado na validacao cruzada

train_control_BAD = trainControl(method = "cv", number = 4,
                                 search = "grid", allowParallel = TRUE)


# Estabelecendo um grid a ser usado (Fixar mtry como a raiz quadrada de ncol)

tg_model = expand.grid(.mtry = as.integer(sqrt(ncol(db_balanced))))


# Criando um modelo de Random Forest

model = train(BAD ~ .,
              data = db_balanced, trControl = train_control_BAD, 
              method = "rf", nodesize = 2, ntree = 100, tuneGrid = tg_model, 
              importance = TRUE)

# Informacoes Gerais do modelo

print(model)

  ## OBS: O Tuning de Hiperparametros foi feito manualmente! E de conhecimento de todos que o correto seria montar um grid com a lista de valores a ser considerado para ajuste do modelo, mas por questao de eficiencia (visto que o processo de tuning e algo demorado) foi feito uma metodologia de tentativa e erro fixando um parametro e alterando os demais para cada um dos parametros a serem ajustados.
```


Testando o modelo em train_db e criando uma matriz confusao para verificar o percentual de acerto:
```{r Modelo de ML em train_db}
# Fazendo as previsoes em cima de test_db:

predTRAIN_BAD = predict(object = model, newdata = train_db)


# Matriz Confusao do modelo

mcTRAIN_BAD = table(as.data.frame(train_db)[, "BAD"], 
                       as.data.frame(predTRAIN_BAD)[, 1])

confusionMatrix(mcTRAIN_BAD)
```


Agora submetendo a test_db e criando a matriz confusao
```{r Modelo de ML em test_db}
# Fazendo as previsoes em cima de test_db:

predTEST_BAD = predict(object = model, newdata = test_db)


# Matriz Confusao do modelo

mcTEST_BAD = table(as.data.frame(test_db)[, "BAD"], 
                        as.data.frame(predTEST_BAD)[, 1])
 
 
confusionMatrix(mcTEST_BAD)
```


Feature Importance
```{r Feature Importance}
# Analisando graficamente o Feature Importance de cada parametro

plot(varImp(model), main = "Variable Importance")
```


Metricas de Avaliacao do Modelo
```{r Metricas de Avaliacao do Modelo}

# 1 - Plotando AUC das bases de treino e teste: ROC pode ser considerado como a curva de probabilidade que nos diz o quanto o modelo e capaz de distinguir classes diferentes de target. AUC nos da esse valor!

  ## Treino: 

      roc.curve(train_db$BAD, predTRAIN_BAD, main = "Train Database ROC")

  ## Teste:

      roc.curve(test_db$BAD, predTEST_BAD, main = "Test Database ROC")
  
  
# 2 - Verificando o F1 score: Utilizado para medir sistemas de classificacao binarios. Combina as metricas "precision" (A relacao da quantidade de dados positivos com os quais o modelo de fato classificou como positivo) e "recall" (E a sensitividade, ou seja, a fracao de dados classificados como positivos em relacao ao numero total de positivos na base de dados) e e considerada a media harmonica desses 2 fatores
  
  ## Treino:
      
      F1_trainScore = F1_Score(as.data.frame(train_db)[, "BAD"], 
                              as.data.frame(predTRAIN_BAD)[, 1])
  
  ## Treino:
      
      F1_testScore = F1_Score(as.data.frame(test_db)[, "BAD"], 
                          as.data.frame(predTEST_BAD)[, 1])


print(paste0("F1 Train Score = ", F1_trainScore))
print(paste0("F1 Test Score = ", F1_testScore))

```


Testando em db_scale (Base Original tratada) para buscar relacoes e aprimorar mais o modelo
```{r ML em db_scale}
# Fazendo as previsoes em cima de db_scale:

pred_db_BAD = predict(object = model, newdata = db_scale)


# Matriz Confusao do modelo

mcDB_BAD = table(as.data.frame(db_scale)[, "BAD"], 
                       as.data.frame(pred_db_BAD)[, 1])

confusionMatrix(mcDB_BAD)
```


Algumas conclusões
```{r Algumas conclusoes}

    # 1 - Foram testados diversos modelos de aprendizado de maquina supervisionados (glm; knn; Neural Networks; etc.)!

    # 2 - A base de dados tinha diversas informacoes que caso tivessem sido preenchidas (ou devidamente preenchidas) agregaria demais ao modelo como 'education', 'mateIncome', 'quantityBankingAcounts' e etc. Sob os dados fornecidos foi realizado o maximo de processos possiveis.

    # 3 - O resultado que eu cheguei foi um modelo considerado "Conservador". Como a base de dados e relativamente desbalanceada e os dados fornecidos sao, ao meu ver, insuficientes para se chegar a um modelo que obtivesse alta precisao e acuracia com equilibrio nas classes, eu decidi construir um modelo de machine learning que fosse mais direcionado a acertar a classe 1, ou seja, de clientes inadimplentes. Afinal, este cliente e considerado um "outlier". Entao no cenario existente, e mais importante o modelo acertar o devedor do que o pagador. 
```


Novo db para analise
```{r Gerando novo db para nova analise e adicionando o predict a essa base:}

db_study = db


# Adicionando o predict a base de dados:

db_study$predictions = pred_db_BAD


# Filtrando a base por valores previstos incorretamente:

db_study = db_study %>%
  select(everything()) %>%
  filter(BAD != predictions)
```


Grafico de Barras para novos insights considerando BAD != predicitons
```{r Grafico de Barras para Novos Insights}
variables_study1 = list("gender", "maritalStatus", "age", "flagResidencialPhone", "areaCodeResidencialPhone")
  
list_study1 = list()
  
  for (i in variables_study1) {
    db_studyBAR1 = ggplot(db_study, aes_string(x = i, 
                                               fill =                       
                                                 as.factor(db_study$BAD))) +
      geom_bar(width = 0.9) +
      theme_minimal()
    list_study1[[i]] = db_studyBAR1
  }
plot_grid(plotlist = list_study1, nrow = 3, ncol = 2)

  
# Das Proximas variaveis:
  
variables_study2 = list("bestPaymentDay", "shopRank","residenceType", "monthsInResidence", "flagMothersName",  "flagFathersName")
  
list_study2 = list()
  
  for (i in variables_study2) {
    db_studyBAR2 = ggplot(db_study, aes_string(x = i, 
                                               fill =
                                                 as.factor(db_study$BAD))) +
      geom_bar(width = 0.9) +
      theme_minimal()
    list_study2[[i]] = db_studyBAR2
  }
plot_grid(plotlist = list_study2, nrow = 3, ncol = 2)

  
# Das Ultimas variáveis:

variables_study3 = list("flagResidenceTown_WorkingTown",
                    "flagResidenceState_WorkingState", "monthsInTheJob",
                    "professionCode",
                    "flagResidencialAddress_PostalAddress", "personalNetIncome")
  
list_study3 = list()
  
  for (i in variables_study3) {
    db_studyBAR3 = ggplot(db_study, aes_string(x = i, 
                                               fill = 
                                                 as.factor(db_study$BAD))) +
      geom_bar(width = 0.9) +
      theme_minimal()
    list_study3[[i]] = db_studyBAR3
  }
  plot_grid(plotlist = list_study3, nrow = 4, ncol = 2)
```


Verificando Proporcoes das Classes que chamaram atencao (Retroalimentado e Modificado) [NOT RUN]
```{r Verificando Proporcoes das Classes que chamaram atencao}

prop_list = list("flagResidencialPhone", "flagResidenceTown_WorkingTown", "shopRank")

for (i in prop_list) {
  a = db_study %>% 
    select(X, i, BAD)
  print(paste(i, sep = "\n"))
  print(prop.table(table(a[, 2])))
}


count_list = list("areaCodeResidencialPhone", "professionCode")
for (i in count_list) {
  b = db_study %>% 
    select(X, i, BAD)
  print(paste(i, sep = "\n"))
  print(table(b[, 2]))
}

  ## [NOT RUN] a) Verificando as relacoes, pode-se ver que nos registros em que os dados foram mal previstos em comparacao ao target talvez seja possivel obter um ganho de informacao pelas variaveis flagResidencialPhone e flagResidencialTown_WorkingTown.
  
  ## [NOT RUN] b) No caso das variaveis "code", alguns valores se sobressaem em relacao aos demais. Em areaCodeResidencialPhone, os numeros 31 e 50 sao fatias significativas, enquanto que em professionCode 950 e 999 tambem apresentam um numero da quantidade absoluta de dados relevantes.
  
  ## Essas variaveis/classes foram adicionadas ao modelo logo no inicio, entao nao e preciso rodar o codigo
```